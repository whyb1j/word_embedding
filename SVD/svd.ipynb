{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\allcodes\\\\nlp\\\\try\\\\SVD'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix,save_npz,load_npz\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "class svd_embedding():\n",
    "    \"\"\"实现了svd降维构建词向量\n",
    "\n",
    "    输入的训练集文本要求以空白字符为间隔\n",
    "\n",
    "    Attributes:\n",
    "        train_path: str 训练集路径\n",
    "        test_path: str 测试集路径\n",
    "        save_dir: str 保存目录\n",
    "        text: list 处理好的文本内容\n",
    "        vocab: set 处理好的词汇表\n",
    "        word2idx: dict 单词对应的索引\n",
    "        idx2word: dict 索引对应的单词\n",
    "        co_matrix: coo 稀疏矩阵\n",
    "        english_stopwords list 停用词列表\n",
    "        stemmer PorterStemmer 词干提取器\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, train_path: str, test_path: str, K: int, dim: int, save_dir: str = 'svd_data'):   \n",
    "        \"\"\"初始化\n",
    "\n",
    "        Args:\n",
    "            train_path: 训练集路径\n",
    "            test_path: 测试数据路径\n",
    "            K: 滑动窗口大小\n",
    "            dim: 词向量维度\n",
    "            save_dir: 数据保存目录\n",
    "        \"\"\"\n",
    "        self.train_path=train_path\n",
    "        self.test_path=test_path\n",
    "        self.K=K\n",
    "        self.dim=dim\n",
    "        self.english_stopwords = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        if not os.path.isdir(save_dir):   \n",
    "            os.mkdir(save_dir)\n",
    "        self.save_dir=save_dir\n",
    "    def read_data(self):\n",
    "        \"\"\"读取训练集文本,对文本做如下处理:小写化,词干提取,去除停用词 \n",
    "        \n",
    "        处理前的vocab_size=253854,text_size=17005207\n",
    "        \"\"\"\n",
    "        print('---开始读数据---')\n",
    "        path=os.path.join(self.save_dir,'text.npy')\n",
    "        if os.path.exists(path):\n",
    "            print('---直接加载已有数据---')\n",
    "            self.text=np.load(path)\n",
    "        else:\n",
    "            with open(self.train_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read().lower().split()\n",
    "            text = [word for word in text if word not in self.english_stopwords]\n",
    "            self.text = [self.stemmer.stem(word) for word in text]#>>10890638\n",
    "            np.save(path,self.text)\n",
    "        #不用set是因为集合的无序性，对集合迭代单词和索引的映射会出问题\n",
    "        #当你创建一个set对象时，它的元素会根据它们被添加到集合中的顺序来迭代，但是每次读取text时顺序都不一样\n",
    "        #即使set本身并不保证元素的顺序。这种行为是为了保证迭代的一致性，特别是当你在遍历集合时使用enumerate函数时。\n",
    "        self.vocab=set(self.text)  #>>201626\n",
    "        #这一步是为了保证每次得到的word2idx是一样的\n",
    "        sorted_vocab = sorted(self.vocab, key=lambda x: (len(x), x))\n",
    "        self.word2idx={word:idx for idx,word in enumerate(sorted_vocab)}\n",
    "        self.idx2word={idx:word for idx,word in enumerate(sorted_vocab)}\n",
    "    def create_co_matrix(self):\n",
    "        \"\"\"创建共现矩阵\n",
    "        \"\"\"\n",
    "        print('---开始创建共现矩阵---')\n",
    "        path=os.path.join(self.save_dir,'co_matrix.npz')\n",
    "        if os.path.exists(path):\n",
    "            print('---直接加载已有的共现矩阵---')\n",
    "            co_matrix=load_npz(path)\n",
    "        else:\n",
    "            row=[]\n",
    "            col=[]\n",
    "            count=[]\n",
    "            for i in range(len(self.text)) :\n",
    "                center_word=self.word2idx[self.text[i]]\n",
    "                #在句子中的位置\n",
    "                window=list(range(max(0,i-self.K),min(i+1+self.K,len(self.text))))\n",
    "                window.remove(i)\n",
    "                for j in window :\n",
    "                    #要转换为index\n",
    "                    if center_word!=self.word2idx[self.text[j]] :\n",
    "                        row.append(center_word)\n",
    "                        col.append(self.word2idx[self.text[j]])\n",
    "                        count.append(1)\n",
    "            co_matrix = coo_matrix((count, (row, col)), shape=(len(self.vocab),len(self.vocab)),dtype=np.float32)\n",
    "            save_npz(path, co_matrix)\n",
    "        self.co_matrix=co_matrix\n",
    "    def svd(self):\n",
    "        \"\"\"奇异值分解\n",
    "        \"\"\"\n",
    "        print('---开始进行奇异值分解---')\n",
    "        path=os.path.join(self.save_dir,f'U_{self.dim}.npy')\n",
    "        if os.path.exists(path):\n",
    "            print('---直接加载降维后的矩阵---')\n",
    "            U=np.load(path)\n",
    "            S=np.load(os.path.join(self.save_dir,f'S_{self.dim}.npy'))\n",
    "        else:\n",
    "            U, S, Vt = svds(self.co_matrix, k=self.dim)\n",
    "            np.save(path, U)\n",
    "            np.save(os.path.join(self.save_dir,f'S_{self.dim}.npy'),S)\n",
    "        self.vec_svd = U\n",
    "        self.S = S\n",
    "    def evaluate(self):\n",
    "        \"\"\"计算文本中两个词之间的余弦相似度\n",
    "        \"\"\"\n",
    "        print('---开始评测---')\n",
    "        result=[]\n",
    "        with open(self.test_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.lower().split()\n",
    "                word1,word2=parts[1],parts[2]\n",
    "                word1,word2=self.stemmer.stem(word1),self.stemmer.stem(word2)\n",
    "                if word1 in self.vocab and word2 in self.vocab:\n",
    "                    index1 = self.word2idx[word1]\n",
    "                    index2 = self.word2idx[word2]  \n",
    "                    # 计算余弦相似度\n",
    "                    vec1 = self.vec_svd[index1]\n",
    "                    vec2 = self.vec_svd[index2]\n",
    "                    cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "                else:\n",
    "                    # 若有词不在词汇表中，将相似度设为0\n",
    "                    cosine_sim = 0.0\n",
    "                temp=line.split()\n",
    "                temp.append(cosine_sim)\n",
    "                result.append(temp)\n",
    "        self.result=result\n",
    "        path=os.path.join(self.save_dir,f'output_svd_{self.dim}.txt')\n",
    "        print(\"---保存结果---\")\n",
    "        with open(path, 'w') as file:\n",
    "            # 遍历结果列表\n",
    "            for item in result: \n",
    "                # 将每个元素转换为字符串，并以制表符分隔\n",
    "                line = '\\t'.join(map(str, item))\n",
    "                # 写入文件\n",
    "                file.write(line + '\\n')\n",
    "    def algorithm(self):\n",
    "        self.read_data()\n",
    "        self.create_co_matrix()\n",
    "        self.svd()\n",
    "        self.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---开始读数据---\n",
      "---直接加载已有数据---\n",
      "---开始创建共现矩阵---\n",
      "---直接加载已有的共现矩阵---\n",
      "---开始进行奇异值分解---\n",
      "---开始评测---\n",
      "---保存结果---\n"
     ]
    }
   ],
   "source": [
    "word2vec_svd=svd_embedding('../original_data/lmtraining.txt','../original_data/wordsim353_agreed.txt',5,50)\n",
    "word2vec_svd.algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2827.8445   2833.0168   2869.4658   2938.7349   2959.5066   3042.4155\n",
      "   3049.2043   3146.0588   3185.3877   3343.7766   3349.6362   3512.297\n",
      "   3672.0303   3750.6775   3765.3425   3938.4385   3966.8196   3994.3284\n",
      "   4254.688    4349.4297   4975.0454   5167.2183   5254.0283   5321.326\n",
      "   5643.5796   5684.9385   6100.3647   6202.9136   6225.487    6695.5967\n",
      "   6908.9146   6991.962    7592.2114   8677.195    8834.363    9010.423\n",
      "   9232.137    9950.05    12275.349   13354.026   31114.227   33733.453\n",
      "  34978.53    36900.863   39039.37    46259.254   46391.785   90511.055\n",
      " 202864.78   399711.8   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2130227.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=word2vec_svd.S\n",
    "print(s[49:-1])\n",
    "np.sum(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
