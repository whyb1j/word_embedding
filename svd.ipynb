{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix,save_npz,load_npz\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "class svd_embedding():\n",
    "    \"\"\"实现了svd降维构建词向量\n",
    "\n",
    "    输入的训练集文本要求以空白字符为间隔\n",
    "\n",
    "    Attributes:\n",
    "        train_path: str 训练集路径\n",
    "        test_path: str 测试集路径\n",
    "        save_dir: str 保存目录\n",
    "        text: list 处理好的文本内容\n",
    "        vocab: set 处理好的词汇表\n",
    "        word2idx: dict 单词对应的索引\n",
    "        idx2word: dict 索引对应的单词\n",
    "        co_matrix: \n",
    "        english_stopwords\n",
    "        stemmer\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, train_path: str, test_path: str, K: int, dim: int, save_dir: str = 'svd_data'):   \n",
    "        \"\"\"初始化\n",
    "\n",
    "        Args:\n",
    "            train_path: 训练集路径\n",
    "            K: 滑动窗口大小\n",
    "\n",
    "        \"\"\"\n",
    "        self.train_path=train_path\n",
    "        self.test_path=test_path\n",
    "        self.K=K\n",
    "        self.dim=dim\n",
    "        self.english_stopwords = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        if not os.path.isdir(save_dir):   \n",
    "            os.mkdir(save_dir)\n",
    "        self.save_dir=save_dir\n",
    "        self.algorithm()\n",
    "    def read_data(self):\n",
    "        \"\"\"读取训练集文本,对文本做如下处理:小写化,词干提取,去除停用词 \n",
    "        \n",
    "        处理前的vocab_size=253854,text_size=17005207\n",
    "        \"\"\"\n",
    "        print('---开始读数据---')\n",
    "        path=os.path.join(self.save_dir,'text.npy')\n",
    "        if os.path.exists(path):\n",
    "            print('---直接加载已有数据---')\n",
    "            self.text=np.load(path)\n",
    "        else:\n",
    "            with open(self.train_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read().lower().split()\n",
    "            text = [word for word in text if word not in self.english_stopwords]\n",
    "            self.text = [self.stemmer.stem(word) for word in text]#>>10890638\n",
    "            np.save(path,self.text)\n",
    "        #不用set是因为集合的无序性，对集合迭代单词和索引的映射会出问题\n",
    "        #误会了。\n",
    "        #当你创建一个set对象时，它的元素会根据它们被添加到集合中的顺序来迭代，\n",
    "        #即使set本身并不保证元素的顺序。这种行为是为了保证迭代的一致性，特别是当你在遍历集合时使用enumerate函数时。\n",
    "        self.vocab=set(self.text)  #>>201626\n",
    "        self.word2idx={word:idx for idx,word in enumerate(self.vocab)}\n",
    "        self.idx2word={idx:word for idx,word in enumerate(self.vocab)}\n",
    "    def create_co_matrix(self):\n",
    "        \"\"\"创建共现矩阵\n",
    "\n",
    "        \"\"\"\n",
    "        print('---开始创建共现矩阵---')\n",
    "        path=os.path.join(self.save_dir,'co_matrix.npz')\n",
    "        if os.path.exists(path):\n",
    "            print('---直接加载已有的共现矩阵---')\n",
    "            co_matrix=load_npz(path)\n",
    "        else:\n",
    "            row=[]\n",
    "            col=[]\n",
    "            count=[]\n",
    "            for i in range(len(self.text)) :\n",
    "                center_word=self.word2idx[self.text[i]]\n",
    "                #在句子中的位置\n",
    "                window=list(range(max(0,i-self.K),min(i+1+self.K,len(self.text))))\n",
    "                window.remove(i)\n",
    "                for j in window :\n",
    "                    #要转换为index\n",
    "                    if center_word!=self.word2idx[self.text[j]] :\n",
    "                        row.append(center_word)\n",
    "                        col.append(self.word2idx[self.text[j]])\n",
    "                        count.append(1)\n",
    "            co_matrix = coo_matrix((count, (row, col)), shape=(len(self.vocab),len(self.vocab)),dtype=np.float32)\n",
    "            save_npz(path, co_matrix)\n",
    "        self.co_matrix=co_matrix\n",
    "    def svd(self):\n",
    "        print('---开始进行奇异值分解---')\n",
    "        U, S, Vt = svds(self.co_matrix, k=self.dim)\n",
    "        path=os.path.join(self.save_dir,'U_k.npy')\n",
    "        np.save(path, U)\n",
    "        self.vec_svd = U\n",
    "    def evaluate(self):\n",
    "        print('---开始评测---')\n",
    "        result=[]\n",
    "        with open(self.test_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.lower().split()\n",
    "                word1,word2=parts[1],parts[2]\n",
    "                word1,word2=self.stemmer.stem(word1),self.stemmer.stem(word2)\n",
    "                if word1 in self.vocab and word2 in self.vocab:\n",
    "                    index1 = self.word2idx[word1]\n",
    "                    index2 = self.word2idx[word2]  \n",
    "                    # 计算余弦相似度\n",
    "                    vec1 = self.vec_svd[index1]\n",
    "                    vec2 = self.vec_svd[index2]\n",
    "                    cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "                else:\n",
    "                    # 若有词不在词汇表中，将相似度设为0\n",
    "                    cosine_sim = 0.0\n",
    "                temp=line.split()\n",
    "                temp.append(cosine_sim)\n",
    "                result.append(temp)\n",
    "        self.result=result\n",
    "        path=os.path.join(self.save_dir,'output_svd.txt')\n",
    "        with open(path, 'w') as file:\n",
    "            # 遍历结果列表\n",
    "            for item in result: \n",
    "                # 将每个元素转换为字符串，并以制表符分隔\n",
    "                line = '\\t'.join(map(str, item))\n",
    "                # 写入文件\n",
    "                file.write(line + '\\n')\n",
    "    def algorithm(self):\n",
    "        self.read_data()\n",
    "        self.create_co_matrix()\n",
    "        self.svd()\n",
    "        self.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---开始读数据---\n",
      "---直接加载已有数据---\n",
      "---开始创建共现矩阵---\n",
      "---开始进行奇异值分解---\n",
      "---开始评测---\n"
     ]
    }
   ],
   "source": [
    "word2vec_svd=svd_embedding('lmtraining.txt','wordsim353_agreed.txt',5,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
